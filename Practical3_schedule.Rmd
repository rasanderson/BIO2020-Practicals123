---
title: 'Practical 3: Multiple explanatory variables'
author: "BIO2020"
output: word_document
---

```{r setup, include=FALSE}
library(bio2020)
knitr::opts_chunk$set(echo = TRUE)
pea_dat <- read.csv("Data/Peas.csv")
```

# Introduction
Now that we have developed a good understanding of linear models we are going to look at some more complex cases. The overall aim is to ensure that you are familiar with the use of linear models and the `lm()` function when you have multiple explanatory variables. This might arise in 'block' designed experiments, mixtures of continuous and categorical explanatories, and curve fitting. You will also have the opportunity to gain more confidence and expertise in manipulating and plotting your data. Specific objectives are to:

1. Explore the use of blocked experimental design, and how to analyse them
2. Understand interaction terms, and how to interpret them
3. Linear models with both categorical and continuous explanatory variables
4. Fitting curves to your data with `lm()`

# 1. Blocked experiments
## 1.1 Refresher on basic concepts
Recall from [Interactive Website on Blocking](https://naturalandenvironmentalscience.shinyapps.io/multiple_explan/#section-blocking) that we use block designs to increase our ability to detect a treatment effect. In the linear models we have looked at so far, there has only been one explanatory variable, so we can think of it as:

$$Response = Explanatory + \epsilon$$
where:

* $Explanatory$ = your treatment, e.g. fertiliser (control, nitrogen, phosphorous)
* $Response$ = dependent variable, e.g. crop growth as a result of fertiliser
* $\epsilon$ = Greek letter Epsilon which stands for the unknown noise or variation in your data

If you are doing a field or laboratory experiment a common design is the **fully randomised design**. For example, you might have:

* 3 types of antibiotic being tested. You have 5 replicate Petri dishes for each antibiotic, and you randomly assign each antibiotic to one of the Petri dishes. You put all 15 Petri dishes on a tray into the incubator.
* 4 varieties of tomato plant are being grown, and you want to measure the chlorophyll content of their leaves. You grow up 6 replicate seedlings of each variety, randomly put them into different pots in a glasshouse
* 3 fertilisers plus a control (4 treatment levels) and you want to understand their effects on growth of pea plants. You create 6 plots (3 m x 3m) for each replicate giving 24 replicates in total, and allocate the fertilisers at random and later assess the growth of the pea plants.

Now there is nothing wrong with these fully randomised designs, but the problem is that **they are at greater risk of going wrong**. Purely by chance, you might end up with:

* most of the Petri dishes for one of your 3 antibiotics being near the door of the incubator. These get different and more variable temperatures than those at the back of the incubator.
* the temperature and humidity in the glasshouse are likely to differ on the north and south side of the glasshouse. It might be the one of your four varieties of tomato plants ends up on the north side, and grows more slowly
* there will be natural variation in the soil conditions across the twenty-four 3 m x 3 m plots (216 $m^2$ total area) where you grow your pea plants. If one of your fertiliser treatments ends up mainly on the poor, waterlogged soil this will bias your results.

So we recognise that there is natural variation in your "experimental arena" whether it is a laboratory, glasshouse or field experiment. A fully randomised design is vulnerable to this variation biasing your results. To solve the problem we divide the experimental arena into blocks, and randomly allocate our replicate treatments within each block:

* Divide your laboratory tray into 5 strips with marker pen, arranged so that when you put the tray into the incubator one strip is near the door, the fifth strip near the back of the incubator. Have 3 Petri dishes in each strip, and randomly allocate one of your 3 antibiotics to each of the three Petri dishes.
* Divide your glasshouse into 6 bands from north to south. Within each band, randomly place 4 plant pots containing your four different varieties of tomato.
* Divide your plot experiment with your peas into 6 areas, encompassing everything from the waterlogged soil to the drier soil. Within each area, mark out 4 plots, and randomly allocate the different fertiliser treatments.

These designs are known as **randomised block designs**. You are still allocating treatments to your replicates at random (essential), but you are doing so to **minimise systematic errors** due to so sort of variation in the "experimental arena". You can adopt a similar approach even for ecological field surveys, although it is harder to implement in practice. You can now modify your linear model to:

$$Response = Explanatory + Block + \epsilon$$

The advantage of including an explicit term called $Block$ into your linear model is that it makes the  error or noise ($\epsilon$) term smaller. The bigger the signal-to-noise ratio, which is what your F-ratio measures, the more likely you are to find out whether your $Explanatory$ treatment is doing anything to your $Response$ variable.

## 1.2 Example of a blocked experiment
We will start by using some data that comes from the pea growth and fertiliser experiment mentioned above. The data are available on Canvas in the `Peas.csv` file which you should save to your `Data` folder. Use the `read.csv()` function that your are hopefully now familiar with, import it into `pea_dat`, and use some of  the functions that you have learned about in previous practical sessions to explore the data.
 
From your inspections of the data what can you learn?
 
### 1.2.1 Lets talk about the 'shape' of your data
Often when you come to analyse some data you find that the data are stored in a format that is not quite what you want for analysis.
In such instances you may need to manipulate your data or reshape it so that you can carry out your analyses or create your plots.
This course is primarily focused on understanding the statistical principles that will enable you to rigorously inspect data that you come across rather than on data manipulation in R.
That being said it's all very well knowing how to analyse your data but if you can't get your data into the correct format you aren't going to be able to carry out your analyses.
We will walk you through the transformation here and if you want to learn more data manipulation skills you can work through an online tutorial such as [this](https://datacarpentry.org/R-ecology-lesson/03-dplyr.html).
The data are currently in what is referred to as `wide format` 
Use the `head()` function to look at the structure of the data as we currently have it.

```{r echo = FALSE}
head(pea_dat)
```

We have columns containing the yield values resulting from each treatment. This is the easiest way to enter the data into Microsoft Excel, so you will often record or receive data like this.
To compare the effects of the treatments on the yield values it would be more useful to have the yield values as a column alongside a column detailing the treatment.
This is what is referred to as `long format` data where each row contains a single observation. 


```{r echo = FALSE}
knitr::include_graphics("images/Pivot_longer.png")
```

You may have noticed that in the previous practical we used the `pivot_longer()` function (`r emo::ji("package")` `tidyr`) on some similar data. The `tidy` package is auto-loaded by both the `mosaic` and `bio2020` packages.
We are going to use that same function here to switch our data set from `wide` to `long`
We will create a new object called `pea_dat_long`. We will retain the original format of the data unchanged in `pea_dat` which might be useful for comparison.

*Remember* you can inspect the help file for the function in the help tab, this will help you to understand what arguments the function is expecting

```{r}
# remember to load the tidyr package; you can do this via library(tidyr), library(mosaic) or library(bio2020)
library(bio2020)

# reshape the data
pea_dat_long <- pivot_longer(
  data = pea_dat,
  cols = NitroGrow:Control,
  names_to = "Treatment",
  values_to = "Yield"
)
```

There are four `arguments` to the `pivot_longer()` function:

* `data` This is the name of your original "wide" dataset. The word `data=` is optional as the function assumes this will be the first term.
* `cols` These are the columns that we want to stack up one on top of another to create a new named column. The `:` symbol indicates that we want to go from the column called `NitroGrow` all the way consecutively to the column called `Control`
* `names_to` This is the name we want to give to a new column that will identify whether we have a record from `NitroGrow`, `PowerGro`, `Nitro.Power` or `Control`. These are the different levels of our new, single "explanatory" variable, so we will call it `"Treatment"` (double-quotes needed)
* `values_to` which are the actual numbers of the yield of peas, will be stacked into a new column, which we will call `"Yield"` (double-quotes needed)

You might have spotted that the fifth column, `Block`,in our original "wide" dataset `pea_dat` is not mentioned in the `pivot_longer()` function. Since we omitted it, R will leave it unchanged, but automatically fill out the number of repetitions needed. To look at your long set of data, either enter `View(pea_dat_long)` in the R Console window, or double-click on its name in the Envionment window.


### 1.2.2 Simple exploration of pea data
Now that you have your data in long format you should be able to calculate some simple statistics and visualise it before going ahead with an analysis via a linear model. Do some initial queries to check:

* Overall mean yield across all the plots; use
  + `summary(pea_dat_long)` which also gives minimum, maximum etc., 
  + `mean(Yield ~ NULL, data=pea_dat_long)` or
  + `mean(~Yield, data=pea_dat_long)`
* Standard deviation of `Yield`
* Standard error of `Yield` (**hint**: look back at practical 1)

**Question** When you used the `summary()` function, what did it return for the `Block` variable and the `Treatment` variable?

See if you can produce a boxplot similar to this using the `gf_boxplot()` function, combined with `%>%`, `gf_labs()` and `gf_refine()` with `theme_classic()`. Build it up line-by-line if unsure:

```{r, echo=FALSE}
gf_boxplot(Yield ~ Treatment, data=pea_dat_long) %>% 
  gf_labs(x = "Experimental treatment", y = "Yield of peas per plot (g)") %>% 
  gf_refine(theme_classic())

```

If you are feeling confident, can you remember how to make a violin plot similar to this? **Hint** Replace `gf_boxplot()` with `gf_violin()`, and use the `draw_quantiles = 0.5` option to add the median and `colour = ~Treatment` for colour-coding. The `gf_sina()` function adds the raw data points.

```{r, echo=FALSE}
gf_violin(Yield ~ Treatment, colour = ~Treatment, data=pea_dat_long, draw_quantiles = 0.5) %>% 
  gf_labs(x = "Experimental treatment", y = "Yield of peas per plot (g)") %>% 
  gf_sina() %>% 
  gf_refine(theme_classic())

```


## 1.3 Linear models of the pea data
### 1.3.1 Recoding `Block` and `Treatment`
You may have noticed that when you ran the `summary()` function earlier it returned the minimum, maximum, average etc. of your `Block` variable. This is of course nonsensical. You could just as easily have coded your six blocks A, B, C, D, E and F. Unfortunately, if you leave `Block` unchanged, R will assume it is a continuous variable, and that `Block 6` is "bigger" than `Block 1`. Likewise, the "character" class for `Treatment` is a little confusing, as it does not show the individual fertiliser treatments. We can re-code both variables into factors, and re-run the `summary()` function to see the difference. Remember that the `$` symbol allows us to access individual columns in a table ("data frame") and the `as.factor()` function tells R that the variable is categorical:

```{r}
pea_dat_long$Block <- as.factor(pea_dat_long$Block)
pea_dat_long$Treatment <- as.factor(pea_dat_long$Treatment)
summary(pea_dat_long)
```

That is much better. We no longer have silly statistics for the `Block` column, and the individual fertiliser treatments are now being displayed for the `Treatment`. What do the numbers `4` and `6` represent alongside each row of these entries?

### 1.3.2 Linear models of pea dataset with and without `Block`
We'll begin with a simple linear model that ignores the `Block` variable, just to demonstrate the improvement afterwards.

```{r}
pea_dat_lm1 <- lm(Yield ~ Treatment, data=pea_dat_long)
anova(pea_dat_lm1)
```

What do you conclude from this? Do the fertilisers have a significant effect? How would your report these data? Remember that by convention p=0.05 is usually the critical cut-off for "statistical significance" so what would be an appropriate way to report your results? Do a QQ plot of the residuals? Are assumptions of the model robust?

Now repeat but include `Block`. Notice that we are naming our second set of results `pea_dat_lm2`. This is a common convention in R, to end the name of the output with the name of the analysis (here `lm`) and if doing several models to add a suffix `1`, `2` etc. for clarity:


```{r}
pea_dat_lm2 <- lm(Yield ~ Treatment + Block, data=pea_dat_long)
anova(pea_dat_lm2)
```
 
Notice how the `Treatment` for your fertilisers is now significant. There are several points to notice here:

* The total Sums of Square (a measure of total variation in your dataset) in the data is unchanged in both `lm1` and `lm2` of your pea yield. See [This Interactive Website](https://naturalandenvironmentalscience.shinyapps.io/how_anova_works/#section-variances-with-categorical-explanatory-variables) to remind yourself of the different components of SS
* The **Residuals** are **much smaller** in `pea_dat_lm2`. Residuals are unexplained noise, or the $\epsilon$ in your data. The smaller you can make the noise, the more likely you are to detect a treatment effect.
* The SS is the same for your `Treatment` in both `pea_dat_lm` and `pea_dat_lm2`
* Variance explained by each term is measured in the column headed `Mean Sq` by dividing the `Sum sq` by `Df` (degrees of freedom)
* The `F value` for the fertiliser treatment is calculated by dividing its `Mean Sq` by that of the Residuals. The bigger the F-ratio the more significant (lower p-value), i.e.
   + F-ratio = Treatment Mean Sq / Residual Mean sq
   + `pea_dat_lm1`  F-value = 86.427 / 30.251 = 2.857 (non-significant)
   + `pea_dat_lm2`  F-value = 86.427 / 17.349 = 4.982 (significant)

So what changed was that we moved some of the variation in your data out of "noise" and into "Block". This allowed us to focus on what we were interested in, namely the fertiliser treatment. As before, check the residuals of your second linear model, and create a QQ plot.

### 1.3.2 Which fertiliser treatment is best?
Of course, the above analysis merely shows us that fertiliser has an effect on yield. We also want to know how one fertiliser compares with the others, as well as the Control. So we need to do a Tukey multiple comparison test, using the `TukeyHSD()` function. Try running the `TukeyHSD()` function on the `pea_dat_lm2` results. You'll see that it gives a huge amount of results, because not only does it compare all the pairwise Fertiliser combinations, it also does the same for all the Blocks. We are not interest in Block pairwise comparisons, so we can force the function to only look at the fertilisers via:

```{r, eval=FALSE}
TukeyHSD(pea_dat_lm2, which="Treatment")
```

Next, create a plot of the results of the Tukey test. Ask a demonstrator or member of staff if you are unsure how to interpret the results.

# 2. Interactions terms: when the explanatory variables are not independent
## 2.1 What are interaction terms?
Interaction terms can be useful in both designed experiments and field surveys. They provide a way of checking whether the effects of two explanatory variables on the response are independent of each other, or alternatively whether the value of one explanatory variable alters what the other one does.

## 2.2 Basic concepts in the 'goal-oriented' approach
Our original linear model, with two explanatory variables is

$$Response = \textit{Explanatory 1} + \textit{Explanatory 2} + \epsilon$$
and we revise this to:

$$Response = \textit{Explanatory 1} + \textit{Explanatory 2} + \textit{Interaction} + \epsilon$$
 
where:

* $Response$ = dependent variable, e.g. crop growth as a result of fertiliser
* $\textit{Explanatory 1}$ = your first treatment, e.g. fertiliser (control, nitrogen, phosphorous)
* $\textit{Explanatory 2}$ = your second treatment, e.g. pesticide (control, insecticide)
* $\textit{Interaction}$ = measures how response variable changes as a result of **both** first and second treatment
* $\epsilon$ = Greek letter epsilon = the unexplained "noise" in your data
 
The $\textit{Explanatory 1}$ and $\textit{Explanatory 2}$ variables can be continuous and/or categorical. You can express an interaction term in R using the `lm()` function, by adding an extra term with the two explanatories separated by a colon `:` symbol. Thus, if your response was `yield`, your two explanatories were `fertiliser` and `pesticide` in a table of data called `crop_data` you would write:

`crop_lm <- lm(yield ~ fertiliser + pesticide + fertiliser:pesticide, data=crop_data)`

Let's look at the example from the [Interactive Website on interaction terms](https://naturalandenvironmentalscience.shinyapps.io/multiple_explan/#section-interactions-between-explanatory-variables)

## 2.3 Example of interactions: blood plasma calcium in rabbits
Let's look at the example of the blood Ca level in rabbits, half from a lowland agricultural farm, half from an upland farm, split according to gender. Download the file `plasma.csv` from Canvas and put it into your **`Data`** folder. Using the `read.csv()` function, import the file into an R table called `plasma_dat`. Now see if you can produce a boxplot similar to the following. **Hints**:

* `gf_boxplot()` is main function
* `gf_labs()` to change default labels
* `gf_refine()` to change overall format of plot

```{r, echo=FALSE}
plasma_dat <- read.csv("Data/plasma.csv")
gf_boxplot(calcium ~ site, colour = ~sex, data=plasma_dat) %>% 
  gf_labs(y = "Blood calcium (mg / 100 ml)", x = "Farm location") %>% 
  gf_refine(theme_classic())

```

 From the plot you can see several trends:
 
 * males seem to have lower blood Ca than females overall
 * in males the blood Ca increases from lowland to upland, whereas for females it decreases
 * the differences between males and females appear to be bigger at lowland than upland farms
 
 You can now create the linear model using `lm()` as usual, but include an interaction term:
 
```{r}
calcium_lm <- lm(calcium ~ site + sex + site:sex, data=plasma_dat)
anova(calcium_lm)
```
 
Notice how your ANOVA table now has **three** rows for the explanatories, namely `site` on the first row, `sex` on the second row, and the interaction term `site:sex` on the third row. When `site` and `sex` are on their own, as on the first and second row, they are referred to as **"main effects"** to distinguish them from when they both occur together in the third row as the interaction term. As usual there is of course a final row for the `Residuals` or unexplained noise ($\epsilon$) in your data. You can see three F-ratios (one for each explanatory variable) and associated p-values, the latter under the column headed `Pr(>F)`.

Before reading on, think about these questions:

* How would you report the above F and p-values in a report?
* Which explanatory variables are "statistically significant"?

## 2.4 How to interpret a linear model with interaction terms
When you have an interaction term as one of your explanatory variables, always look at it **first**. If it is not significant, you might be able to manage with a simpler linear model that does not include interaction terms. It is always best to try and have a simpler rather than overly complex linear model when possible.

However, in this example the interaction term **is** significant. Indeed, you have:

* `site` main effect. $F_{1,16}=0.017, p=0.899$ non-significant
* `sex` main effect. $F_{1,16}=167.658, p<0.001$
* `site:sex` interaction. $F_{1,16}=47.604, p<0.001$

So you can see that both the `site:sex` interaction and `sex` main effect terms are highly significant, whereas the `site` main effect is non-significant. This type of result is not uncommon, but at first glance is very confusing. Why is the `site` main effect unimportant, whilst it seems to have a big impact on blood calcium in the interaction? This seems a little contradictory.

The easiest way to understand the process is to plot individual graphs for each component. See if you can create these graphs on your own.

First of all the `site` main effect:

```{r, echo=FALSE}
gf_boxplot(calcium ~ site, data=plasma_dat)

```

It is fairly obvious that the overall amounts of blood calcium are fairly similar in both the lowland and upland farms, if we ignore gender, although the range of values is smaller in the uplands. A boxplot shows the median as the middle horizontal line (try calculating the means for comparison) and these are quite close to each other. This explains the non-significant `site` main effect.

Second, the sex main effect. Try and produce a graph similar to the following:

```{r, echo=FALSE}
gf_boxplot(calcium ~ sex, data=plasma_dat)
```

Now the sets of values are very different, with the males much lower overall than the females, which explains the large F-ratio and highly significant (p<0.001) results for `sex` main effect.

Finally, the interaction term. As this graph is a little trickier to draw, I have included the R code. We include both the raw data, and lines connecting the means, to show the direction of change:

```{r}
# gf_point() adds the raw data points
# gf_line() adds lines. We use stat="summary" to indicate the mean
gf_point(calcium ~ site, colour= ~sex, data=plasma_dat) %>%
  gf_line(calcium ~ site, colour= ~sex, group= ~sex, stat="summary", data=plasma_dat)
```

The important point to note here is that **the lines are not parallel**. If the lines were paralell, either upwards or downwards, it would indicate that the blood calcium changed in a similar way for both genders when moving from lowland to upland farms. However in reality they are not parallel, indeed the differences are so big that the gradients of the lines go in opposite directions. This indicates that the physiology of male and female rabbits in response to the elevation change is not the same.

To explore these data more [look at this interactive webpage](https://naturalandenvironmentalscience.shinyapps.io/multiple_explan/#section-interactive-demonstration). This uses the same data, but you can randomly adjust some of the terms, and see how the results change. Begin by setting the interaction term to zero, and notice the difference.
 
## Animal weights

```{r echo = FALSE}
pantheria <- read.csv("Data/Pantheria.csv")

```

Lets switch from pants to animals. 
The data contained in the `Pantheria.csv` file contains information from the [Pantheria database](https://ecologicaldata.org/wiki/pantheria)
You have data which details records of weight,head-body length, skull length, home range and density for species from across several families of the order Carnivora.

+ Load the data into R and investigate it
+ Generate some summary statistics and plots that describe your data

You can use this data to practice another common data manipulation technique - filtering
There may be times where we have more data than we want to investigate or plot, in these instances it can be useful to extract only a subset of our data.
The pantheria data for example contains species from several families of carnivores but you might only be interested in one family of animals.
In such instances we can use the `filter` function (`r emo::ji("package")` dplyr) to extract only the subset that we are interested in. 

For example if we wanted to create a data frame that contained only information regarding the Canidae (dog) family we could do the following:

```{r,warning= FALSE, message = FALSE}
#load the package
library(dplyr)
#filter the pantheria data to keep only rows where the Family
#has the value "Canidae"
dog_dat <- filter(pantheria, Family == "Canidae")
```

 You will notice that the data are listed as an object in the Environment pane.
You can inspect an object by clicking on its name, data frames such as that containing information from the `Pantheria.csv` file are displayed in a spreadsheet like manner.
This can be useful for inspecting the data frame, you can scroll through and see what Families are included in the data frame for example.

+ Choose a family to investigate, create a new data frame containing only records from that family
 + Create a plot of the data that shows the relationship between head-body length and skull length for species in your chosen Family
 
Lets return to the full data set and investigate the relationship between **body size** and **weight**.
We have measurements of body length and body weight but what is the relationship between the two?
Do animals get heavier as their bodies get longer?

 + Create a linear model to describe the relationship between body length and body weight
 + Plot your model and evaluate the model (using summary outputs, qq plots etc.)
 + Does the model look like a good fit of the data?
 + How could you improve the fit of your model? 
 
Remember that the relationship might not be linear and might be improved by adding a quadratic term.
You can investigate the addition of a quadratic term or the addition of Family as a grouping variable.
Interrogate these models and determine which you think is the most appropriate or most useful. 

+ Write a paragraph describing your results, include references to your model statistics and any plots that you think are useful.


## Interactions between explanatory variables

As we saw in the previous tutorial our independent variables are not always independent of each other.
In such cases we may need to account for interactions between variables in our models. 

The `Shrub.csv` file contains information on the heights of shrubs (m) growing in soils that are classified as having Low (0), Medium (1) or High (2)  levels of bacteria present in the soil. 
The shrubs are also recorded as growing in areas classed as either partial sun (0) or full sun (1).

It would be useful to add an interaction term to the model if we wanted to test the hypothesis that the relationship between the amount of bacteria in the soil on the height of the shrub was different in full sun than in partial sun.

 + Import the data from the `Shrub.csv` file and familiarize yourself with it.
 + Create some plots of your data, you may what to look for differences between Bacterial loads and sun exposure.
 
 You may have noticed that the data contained in the `Bacteria` and `Sun` variables are coded numerically but are in fact categorical. 
 
 + Re-code the variables so that R recognizes them as categorical rather than numerical
 + Create a linear model in which shrub height is the response variable
 + Create a model with the addition of an interaction term between the two explanatory variables
 
 Remember that the syntax for including interaction terms is as follows 
 
```{r, eval = FALSE}
# the : denotes the interaction
model <- lm(response~ explan1 + explan2 + explan1:explan2, data = dataset)
```
 
 + Is the impact of soil bacteria different if a plant is in full or partial sun?
 + Write a summary of your results including references to model outputs, whether the model assumptions have been met and any figures that you have created. 






